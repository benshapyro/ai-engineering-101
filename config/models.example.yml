# Example model configuration
# Copy to config/models.yml and customize with your actual pricing
#
# IMPORTANT: Prices shown are illustrative examples from September 2025.
# Always verify current pricing at https://openai.com/pricing and https://anthropic.com/pricing
#
# Usage:
#   1. Copy this file: cp config/models.example.yml config/models.yml
#   2. Update prices to match your actual provider pricing
#   3. The curriculum will use these values for cost calculations
#
# Alternative: Set environment variables
#   COST_PER_1M_INPUT=5.00
#   COST_PER_1M_OUTPUT=15.00

openai:
  gpt-5:
    input_per_1m: 5.00        # USD per 1 million input tokens
    output_per_1m: 15.00      # USD per 1 million output tokens
    context_window: 128000    # Maximum context window
    description: "Flagship model with strong reasoning"

  gpt-5-mini:
    input_per_1m: 0.30
    output_per_1m: 1.20
    context_window: 128000
    description: "Cost-efficient variant with good performance"

  gpt-5-nano:
    input_per_1m: 0.10
    output_per_1m: 0.40
    context_window: 16000
    description: "Fastest and cheapest option"

  gpt-5-codex:
    input_per_1m: 6.00
    output_per_1m: 18.00
    context_window: 128000
    description: "Coding-optimized model"

  # Legacy models (for reference)
  gpt-4o:
    input_per_1m: 5.00
    output_per_1m: 15.00
    context_window: 128000
    description: "Previous generation flagship"

  gpt-4o-mini:
    input_per_1m: 0.15
    output_per_1m: 0.60
    context_window: 128000
    description: "Previous generation efficient model"

anthropic:
  claude-sonnet-4-5:
    input_per_1m: 3.00
    output_per_1m: 15.00
    context_window: 200000
    description: "Best quality/cost ratio (released Sept 2025)"

  claude-opus-4-1:
    input_per_1m: 15.00
    output_per_1m: 75.00
    context_window: 200000
    description: "Highest capability model"

  claude-haiku-3-5:
    input_per_1m: 0.80
    output_per_1m: 4.00
    context_window: 200000
    description: "Fast and cost-efficient"

# Add your custom models here
# custom:
#   my-model:
#     input_per_1m: 1.00
#     output_per_1m: 2.00
#     context_window: 32000
#     description: "My custom model"
