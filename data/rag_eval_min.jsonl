{"query": "What is prompt engineering?", "answer": "Prompt engineering is the practice of designing and optimizing prompts to effectively guide large language models toward desired outputs.", "context": ["Prompt engineering is the art and science of crafting effective inputs for LLMs.", "Good prompts are clear, specific, and provide necessary context.", "Prompt engineering techniques include few-shot learning and chain-of-thought."], "relevant_docs": [0, 2]}
{"query": "How do you implement few-shot learning?", "answer": "Few-shot learning is implemented by providing examples in the prompt before the actual query, showing the model the pattern you want it to follow.", "context": ["Few-shot learning involves including examples in your prompt.", "Typically 3-5 examples work well for most tasks.", "Examples should be diverse and representative.", "Few-shot outperforms zero-shot for complex tasks."], "relevant_docs": [0, 1, 3]}
{"query": "What are the benefits of RAG?", "answer": "RAG (Retrieval-Augmented Generation) improves LLM outputs by grounding them in retrieved external knowledge, reducing hallucinations and enabling access to current information.", "context": ["RAG combines retrieval with generation for better accuracy.", "RAG reduces hallucinations by grounding responses in facts.", "RAG enables LLMs to access information beyond training data.", "RAG is essential for knowledge-intensive applications."], "relevant_docs": [0, 1, 2, 3]}
{"query": "Compare temperature settings in LLMs", "answer": "Lower temperature (0.0-0.3) produces focused, deterministic outputs suitable for factual tasks. Higher temperature (0.7-1.5) increases creativity and diversity, better for creative writing.", "context": ["Temperature controls randomness in LLM outputs.", "Low temperature (0.0) is deterministic and focused.", "High temperature (1.5) is creative and diverse.", "Default temperature is usually 0.7 for balanced outputs.", "Use temperature=0 for reproducible testing."], "relevant_docs": [0, 1, 2, 3]}
{"query": "What is the purpose of reranking in RAG?", "answer": "Reranking improves retrieval quality by reordering initially retrieved documents using more sophisticated relevance scoring, typically with cross-encoder models that jointly encode query and document.", "context": ["Reranking refines initial retrieval results.", "Cross-encoders provide better relevance scoring than bi-encoders.", "Reranking is slower but more accurate than initial retrieval.", "Common reranker models include ms-marco-MiniLM.", "Reranking typically operates on top-k initial results (k=20-100)."], "relevant_docs": [0, 1, 2, 4]}
